{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network\n",
    "\n",
    "This notebook shows how to apply convolutional networks to image processing problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:42.704561Z",
     "start_time": "2019-03-09T06:59:39.903541Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the path of the data source for convenience\n",
    "\n",
    "Source of the data is the `train.csv` of https://www.kaggle.com/c/digit-recognizer/data\n",
    "\n",
    "The data with the first 25000 rows is also provided with the code in the `data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:42.713545Z",
     "start_time": "2019-03-09T06:59:42.707545Z"
    }
   },
   "outputs": [],
   "source": [
    "FILE_PATH = '../data/digits.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and view the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:46.571542Z",
     "start_time": "2019-03-09T06:59:42.716538Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILE_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the labels to one-hot encoding\n",
    "\n",
    "This is needed when working with a multi-label problem since the network will predict the probability for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:46.582552Z",
     "start_time": "2019-03-09T06:59:46.576542Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df['label'].values\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:46.624543Z",
     "start_time": "2019-03-09T06:59:46.586540Z"
    }
   },
   "outputs": [],
   "source": [
    "y_encoder = OneHotEncoder(sparse=False)\n",
    "y_encoded = y_encoder.fit_transform(y.reshape(-1, 1))\n",
    "y_encoded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the labels in the set of our input features\n",
    "\n",
    "The data is reshaped with a fourth dimension. This is because the fourth dimension represents the color bands. For example, a normal image has 3 bands (RGB) and this monochromatic data set only has one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:46.806166Z",
     "start_time": "2019-03-09T06:59:46.627547Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df.drop('label', axis=1).values\n",
    "X = X.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the images\n",
    "\n",
    "Show the data to make sure converted the csv rows to their proper images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:48.219420Z",
     "start_time": "2019-03-09T06:59:46.821164Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(X[i].reshape(28, 28))\n",
    "    plt.show()\n",
    "    print('Label:', y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Keras model for training\n",
    "\n",
    "This architecture is similar to a smaller VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:48.339460Z",
     "start_time": "2019-03-09T06:59:48.222421Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ = tf.keras.Input((28, 28, 1))\n",
    "conv1 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(input_)\n",
    "conv2 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv1)\n",
    "mp1 = tf.keras.layers.MaxPool2D((2,2))(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(mp1)\n",
    "conv4 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv3)\n",
    "conv5 = tf.keras.layers.Conv2D(8, (3, 3), activation='relu')(conv4)\n",
    "mp2 = tf.keras.layers.MaxPool2D((2,2))(conv5)\n",
    "fl = tf.keras.layers.Flatten()(mp2)\n",
    "dense1 = tf.keras.layers.Dense(8, activation='relu')(fl)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax')(dense1)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:59:48.408513Z",
     "start_time": "2019-03-09T06:59:48.357422Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model using the training data\n",
    "\n",
    "It's better to use the callbacks used in the previous notebook to better training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T07:03:47.935120Z",
     "start_time": "2019-03-09T06:59:48.410454Z"
    }
   },
   "outputs": [],
   "source": [
    "hst = model.fit(X, y_encoded, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out some predictions\n",
    "\n",
    "It's up to you to try the model performance on a separate training set. The prediction is only done to validate the training operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T07:03:56.028167Z",
     "start_time": "2019-03-09T07:03:47.937121Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(X[i].reshape(28, 28))\n",
    "    plt.show()\n",
    "    print('Prediction:', predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the probabilities to labels\n",
    "\n",
    "Get the index of the largest probability per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(X[i].reshape(28, 28))\n",
    "    plt.show()\n",
    "    print('Prediction:', np.argmax(predictions[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
